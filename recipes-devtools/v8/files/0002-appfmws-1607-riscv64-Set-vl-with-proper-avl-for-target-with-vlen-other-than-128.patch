From 822f0859a094c1673a9f0d5be4904523afa8d5b4 Mon Sep 17 00:00:00 2001
From: Ting Chou <ting.chou@sifive.com>
Date: Tue, 29 Mar 2022 15:41:57 +0800
Subject: [PATCH] [riscv64] Set vl with proper avl for target with vlen other than 128.

---
 src/codegen/riscv64/assembler-riscv64.h                | 2 +-
 src/compiler/backend/riscv64/code-generator-riscv64.cc | 6 ++++--
 2 files changed, 8 insertions(+), 4 deletions(-)

diff --git a/src/compiler/backend/riscv64/code-generator-riscv64.cc b/src/compiler/backend/riscv64/code-generator-riscv64.cc
index c170035ac4..363d958d7d 100644
--- a/src/compiler/backend/riscv64/code-generator-riscv64.cc
+++ b/src/compiler/backend/riscv64/code-generator-riscv64.cc
@@ -1942,7 +1942,8 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       break;
     }
     case kRiscvRvvSt: {
-      (__ VU).set(kScratchReg, VSew::E8, Vlmul::m1);
+      __ li(kScratchReg2, 16);
+      (__ VU).set(kScratchReg, kScratchReg2, VSew::E8, Vlmul::m1);
       Register dst = i.MemoryOperand().offset() == 0 ? i.MemoryOperand().rm()
                                                      : kScratchReg;
       if (i.MemoryOperand().offset() != 0) {
@@ -1952,7 +1953,8 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       break;
     }
     case kRiscvRvvLd: {
-      (__ VU).set(kScratchReg, VSew::E8, Vlmul::m1);
+      __ li(kScratchReg2, 16);
+      (__ VU).set(kScratchReg, kScratchReg2, VSew::E8, Vlmul::m1);
       Register src = i.MemoryOperand().offset() == 0 ? i.MemoryOperand().rm()
                                                      : kScratchReg;
       if (i.MemoryOperand().offset() != 0) {
diff --git a/src/wasm/baseline/riscv64/liftoff-assembler-riscv64.h b/src/wasm/baseline/riscv64/liftoff-assembler-riscv64.h
index 2a157a921a..4502855ba7 100644
--- a/src/wasm/baseline/riscv64/liftoff-assembler-riscv64.h
+++ b/src/wasm/baseline/riscv64/liftoff-assembler-riscv64.h
@@ -558,7 +558,8 @@ void LiftoffAssembler::Load(LiftoffRegister dst, Register src_addr,
       TurboAssembler::LoadDouble(dst.fp(), src_op);
       break;
     case LoadType::kS128Load: {
-      VU.set(kScratchReg, E8, m1);
+      li(kScratchReg2, 16);
+      VU.set(kScratchReg, kScratchReg2, E8, m1);
       Register src_reg = src_op.offset() == 0 ? src_op.rm() : kScratchReg;
       if (src_op.offset() != 0) {
         TurboAssembler::Add64(src_reg, src_op.rm(), src_op.offset());
@@ -622,7 +623,8 @@ void LiftoffAssembler::Store(Register dst_addr, Register offset_reg,
       TurboAssembler::StoreDouble(src.fp(), dst_op);
       break;
     case StoreType::kS128Store: {
-      VU.set(kScratchReg, E8, m1);
+      li(kScratchReg2, 16);
+      VU.set(kScratchReg, kScratchReg2, E8, m1);
       Register dst_reg = dst_op.offset() == 0 ? dst_op.rm() : kScratchReg;
       if (dst_op.offset() != 0) {
         Add64(kScratchReg, dst_op.rm(), dst_op.offset());
-- 
2.25.1

